from flask import Flask, request, jsonify
import tensorflow as tf
import joblib
from tensorflow.keras.preprocessing.sequence import pad_sequences
from better_profanity import profanity
from flask_cors import CORS
import os
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import datetime
from pymongo import MongoClient
import schedule
import time
from bson import ObjectId
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import OneHotEncoder
from prediction.model import BookingLoadPredictor

print("–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–æ...")

# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["computerClub"]
collection = db["devices"]
collectionUsers = db["users"]
price_table_collection = db["priceTable"]

# –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ç–∏–∂–¥–µ–Ω—å
import datetime
today = datetime.datetime.now()
last_week = today - datetime.timedelta(days=7)

bookings = list(collection.find({
    "bookings.startTime": {"$gte": last_week.isoformat()}
}))

processed_data = []

for booking in bookings:
    for entry in booking["bookings"]:
        start_time = datetime.datetime.fromisoformat(entry["startTime"])
        processed_data.append({
            "hour": start_time.hour,
            "dayOfWeek": start_time.weekday(),
            "isWeekend": start_time.weekday() >= 5,
            "zone": booking["zone"]
        })

df = pd.DataFrame(processed_data)

class SentimentModelWithFilter:
    def __init__(self, model_path, tokenizer_path, profanity_file):
        self.model = tf.keras.models.load_model(model_path)
        with open(tokenizer_path, 'rb') as f:
            self.tokenizer = joblib.load(f)
        self.maxlen = 200
        self.load_profanity_list(profanity_file)

    def load_profanity_list(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            bad_words = [line.strip() for line in f if line.strip()]
        profanity.load_censor_words(bad_words)

    def blur_profanity(self, text):
        return profanity.censor(text)

    def predict_sentiment(self, text):
        en_text = text  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç–µ–∫—Å—Ç –±–µ–∑ –ø–µ—Ä–µ–∫–ª–∞–¥—É
        tokenized_text = self.tokenizer.texts_to_sequences([en_text])
        padded_text = pad_sequences(tokenized_text, maxlen=self.maxlen)
        prediction = self.model.predict(padded_text)
        sentiment = "Positive" if prediction[0] > 0.5 else "Negative"

        if prediction[0] > 0.7:
            sentiment = "Positive"
        elif prediction[0] < 0.5:
            sentiment = "Negative"
        else:
            sentiment = "Neutral"

        processed_text = self.blur_profanity(text)
        return sentiment, processed_text

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Flask API
app = Flask(__name__)
CORS(app)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ
model_path = "prediction-model/sentiment_model_amazon100k.h5"
tokenizer_path = "prediction-model/tokenizer_amazon100k.pkl"
profanity_file = "prediction-model/ukrainian-profanity.txt"
sentiment_model = SentimentModelWithFilter(model_path, tokenizer_path, profanity_file)

# === –ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ—Å—Ç—ñ ===
load_model_path = "prediction-model/bookings/booking_load_model.pkl"
zone_encoder_path = "prediction-model/bookings/zone_encoder.pkl"

booking_model = joblib.load(load_model_path)
zone_encoder = joblib.load(zone_encoder_path)

@app.route('/')
def home():
    return "API is running!"

@app.route('/favicon.ico')
def favicon():
    return '', 204

@app.route('/api/analyze', methods=['POST'])
def predict():
    data = request.get_json()
    if not data or 'text' not in data:
        return jsonify({"error": "Invalid input"}), 400

    text = data['text']
    sentiment, processed_text = sentiment_model.predict_sentiment(text)

    return jsonify({
        "original_text": text,
        "processed_text": processed_text,
        "sentiment": sentiment
    })
    
@app.route('/api/price-table', methods=['GET'])
def get_price_table():
    try:
        price_table = list(price_table_collection.find())
        for entry in price_table:
            entry["_id"] = str(entry["_id"])  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è ObjectId —É —Ä—è–¥–æ–∫
        return jsonify(price_table), 200
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ —Ü—ñ–Ω: {e}")
        return jsonify({"error": "Server error"}), 500
    
@app.route('/api/price-table', methods=['POST'])
def update_price_table():
    try:
        data = request.get_json()
        if not data or "zone" not in data or "prices" not in data:
            return jsonify({"error": "Invalid input"}), 400

        zone = data["zone"]
        prices = data["prices"]

        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –∞–±–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–ø–∏—Å—É
        price_table_collection.update_one(
            {"zone": zone},
            {"$set": {"prices": prices}},
            upsert=True
        )

        return jsonify({"message": "Price table updated successfully"}), 200
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ —Ü—ñ–Ω: {e}")
        return jsonify({"error": "Server error"}), 500
    
def calculate_price(zone, duration):
    try:
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ —Ü—ñ–Ω –¥–ª—è –∑–æ–Ω–∏
        price_entry = price_table_collection.find_one({"zone": zone})
        if not price_entry:
            raise ValueError(f"–¶—ñ–Ω–∏ –¥–ª—è –∑–æ–Ω–∏ '{zone}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

        prices = price_entry["prices"]

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–±–ª–∏–∂—á—É —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å
        closest_duration = max([int(d) for d in prices.keys() if int(d) <= duration], default=1)
        return prices[str(closest_duration)]
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —Ü—ñ–Ω–∏: {e}")
        return 0

    
@app.route('/api/predict-load', methods=['POST'])
def predict_booking_load():
    try:
        data = request.get_json()
        start_date = data.get("startDate")
        end_date = data.get("endDate")

        # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç datetime
        start_date = datetime.datetime.fromisoformat(start_date)
        end_date = datetime.datetime.fromisoformat(end_date)

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É
        future_days = [start_date + datetime.timedelta(days=i) for i in range((end_date - start_date).days + 1)]
        print("future_days:", future_days)  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

        processed_data = []
        for day in future_days:
            for hour in range(8, 24):  # –ì–æ–¥–∏–Ω–∏ —Ä–æ–±–æ—Ç–∏ –∫–ª—É–±—É
                for zone in ['Pro', 'VIP', 'PS']:  # –ó–æ–Ω–∏ –∫–ª—É–±—É
                    processed_data.append({
                        "hour": hour,
                        "dayOfWeek": day.weekday(),  # 0 - –ø–æ–Ω–µ–¥—ñ–ª–æ–∫, 6 - –Ω–µ–¥—ñ–ª—è
                        "isWeekend": day.weekday() >= 5,
                        "zone": zone,
                        "date": day.strftime('%Y-%m-%d')  # –î–æ–¥–∞–Ω–æ –¥–∞—Ç—É
                    })

        df = pd.DataFrame(processed_data)
        print("DataFrame –ø–µ—Ä–µ–¥ –∫–æ–¥—É–≤–∞–Ω–Ω—è–º –∑–æ–Ω:", df.head())  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

        # –ö–æ–¥—É–≤–∞–Ω–Ω—è –∑–æ–Ω
        zone_encoded = zone_encoder.transform(df[['zone']])
        zone_cols = zone_encoder.get_feature_names_out(['zone'])
        zone_encoded_df = pd.DataFrame(zone_encoded, columns=zone_cols)

        df = pd.concat([df, zone_encoded_df], axis=1)

        # –ü—Ä–æ–≥–Ω–æ–∑
        X = df[['hour', 'dayOfWeek', 'isWeekend'] + list(zone_cols)]
        print("–§–æ—Ä–º–∞ X:", X.shape)  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
        predictions = np.round(booking_model.predict(X)).astype(int)
        df['prediction'] = predictions

        # –ì—Ä—É–ø—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        if start_date == end_date:
            result = (
                df.groupby(['hour', 'zone'])['prediction']
                .sum()
                .round(1)
                .reset_index()
                .rename(columns={"prediction": "expectedBookings"})
            )

        else:
            result = (
                df.groupby('date')['prediction']
                .sum()
                .round(1)
                .reset_index()
                .rename(columns={"prediction": "expectedBookings"})
            )

        return jsonify(result.to_dict(orient="records"))
    except Exception as e:
        print("‚ùå –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ–º–∏–ª–∫–∞:", str(e))
        return jsonify({"error": str(e)}), 500
    
@app.route('/api/retrain-model', methods=['POST'])
def retrain_model_endpoint():
    result = retrain_model()
    if "error" in result:
        return jsonify(result), 500
    return jsonify(result), 200

def retrain_model():
    try:
        today = datetime.datetime.now()
        last_month = today - datetime.timedelta(days=30)  # –†–æ–∑—à–∏—Ä–µ–Ω–æ –ø–µ—Ä—ñ–æ–¥ –¥–æ –º—ñ—Å—è—Ü—è

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        devices = list(collection.find())

        processed_data = []
        for device in devices:
            if "zone" not in device:
                print(f"‚ùå –ü–æ–ª–µ 'zone' –≤—ñ–¥—Å—É—Ç–Ω—î —É –¥–æ–∫—É–º–µ–Ω—Ç—ñ: {device}")
                continue

            if "bookings" in device and device["bookings"]:
                for entry in device["bookings"]:
                    if "startTime" in entry:
                        start_time = entry["startTime"]
                        if isinstance(start_time, str):
                            start_time = datetime.datetime.fromisoformat(start_time)

                        if start_time >= last_month:
                            processed_data.append({
                                "hour": start_time.hour,
                                "dayOfWeek": start_time.weekday(),
                                "isWeekend": start_time.weekday() >= 5,
                                "zone": device["zone"],
                                "bookings": 1
                            })
            else:
                processed_data.append({
                    "hour": None,
                    "dayOfWeek": None,
                    "isWeekend": None,
                    "zone": device["zone"],
                    "bookings": 0
                })

        print("–û–±—Ä–æ–±–ª–µ–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è DataFrame:", processed_data)

        if not processed_data:
            raise ValueError("‚ùå processed_data –ø–æ—Ä–æ–∂–Ω—ñ–π. –î–∞–Ω—ñ –Ω–µ –±—É–ª–∏ –æ–±—Ä–æ–±–ª–µ–Ω—ñ.")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –¥–∞–Ω–∏—Ö
        file_path = "./prediction-model/bookings/previous_training_data.csv"
        if os.path.exists(file_path):
            previous_data = pd.read_csv(file_path)
        else:
            previous_data = pd.DataFrame(columns=["hour", "dayOfWeek", "isWeekend", "zone", "bookings"])
            previous_data.to_csv(file_path, index=False)  # –ó–±–µ—Ä–µ–∂–µ–Ω—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –¥–∞–Ω—ñ
        new_data = pd.DataFrame(processed_data)

        # –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
        new_data = new_data.fillna({
            "hour": 0,
            "dayOfWeek": 0,
            "isWeekend": False,
            "bookings": 0
        })

        # –û–±'—î–¥–Ω–∞–Ω–Ω—è –Ω–æ–≤–∏—Ö —ñ —Å—Ç–∞—Ä–∏—Ö –¥–∞–Ω–∏—Ö
        combined_data = pd.concat([previous_data, new_data], ignore_index=True)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ–±'—î–¥–Ω–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –º–∞–π–±—É—Ç–Ω—å–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
        combined_data.to_csv("previous_training_data.csv", index=False)

        # –ö–æ–¥—É–≤–∞–Ω–Ω—è –∑–æ–Ω
        if "zone" not in combined_data.columns:
            raise ValueError("–ü–æ–ª–µ 'zone' –≤—ñ–¥—Å—É—Ç–Ω—î —É DataFrame")

        zone_encoded = zone_encoder.transform(combined_data[['zone']])
        zone_cols = zone_encoder.get_feature_names_out(['zone'])
        zone_encoded_df = pd.DataFrame(zone_encoded, columns=zone_cols)

        combined_data = pd.concat([combined_data, zone_encoded_df], axis=1)

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
        X_new = combined_data[['hour', 'dayOfWeek', 'isWeekend'] + list(zone_cols)]
        y_new = combined_data['bookings']

        if X_new.isnull().values.any():
            raise ValueError("‚ùå X_new –º—ñ—Å—Ç–∏—Ç—å NaN. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥–∞–Ω—ñ.")

        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –≤–∞–≥ –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
        weights = [0.2] * len(previous_data) + [0.8] * len(new_data)  # –ú–µ–Ω—à–∏–π –≤–ø–ª–∏–≤ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

        # –î–æ–Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        booking_model.fit(X_new, y_new, sample_weight=weights)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ–Ω–æ–≤–ª–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        joblib.dump(booking_model, load_model_path)
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –¥–æ–Ω–∞–≤—á–µ–Ω–∞ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞.")

        return {"message": "–ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –¥–æ–Ω–∞–≤—á–µ–Ω–∞."}
    except Exception as e:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ:", str(e))
        return {"error": str(e)}
    
def schedule_retraining():
    schedule.every().sunday.at("23:59").do(retrain_model)

    while True:
        schedule.run_pending()
        time.sleep(1)

# –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
import threading
threading.Thread(target=schedule_retraining).start()

@app.route('/api/user-profile/<user_id>', methods=['GET'])
def get_user_profile(user_id):
    try:
        print(f"üîç –ü–æ—à—É–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ ID: {user_id}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        # –í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–π–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ —ñ–∑ user_id
        user_id = user_id.strip("<>")  # –í–∏–¥–∞–ª—è—î–º–æ –∫—É—Ç–æ–≤—ñ –¥—É–∂–∫–∏, —è–∫—â–æ –≤–æ–Ω–∏ —î
        print(f"üîç –û—á–∏—â–µ–Ω–∏–π ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {user_id}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –æ—á–∏—â–µ–Ω–æ–≥–æ ID

        # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è user_id —É ObjectId
        try:
            user_object_id = ObjectId(user_id)
        except Exception as e:
            print(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç ID: {user_id}. –ü–æ–º–∏–ª–∫–∞: {e}")
            return jsonify({"error": "Invalid user ID format"}), 400

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
        user = collectionUsers.find_one({"_id": user_object_id})
        if not user:
            print(f"‚ùå –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ ID {user_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö.")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            return jsonify({"error": "User not found"}), 404

        print(f"‚úÖ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –∑–Ω–∞–π–¥–µ–Ω–∏–π: {user}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤ —ñ–∑ –±—Ä–æ–Ω—é–≤–∞–Ω–Ω—è–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        devices = db.devices.find({"bookings.userId": user_id})
        bookings = []
        for device in devices:
            zone = device.get("zone")  # –û—Ç—Ä–∏–º—É—î–º–æ –∑–æ–Ω—É –∑ –ø—Ä–∏—Å—Ç—Ä–æ—é
            device_type = device.get("type")  # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–∏–ø –ø—Ä–∏—Å—Ç—Ä–æ—é
            for booking in device["bookings"]:
                if booking["userId"] == user_id:
                    bookings.append({
                        "zone": zone,
                        "type": device_type,
                        "startTime": booking["startTime"],
                        "endTime": booking["endTime"],
                        "price": booking["price"]
                    })

        if not bookings:
            print(f"‚ÑπÔ∏è –£ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ ID {user_id} –Ω–µ–º–∞—î –±—Ä–æ–Ω—é–≤–∞–Ω—å.")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            return jsonify({"message": "No bookings found for this user"}), 200

        # –ó–±—ñ—Ä —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        zones = [b["zone"] for b in bookings]
        most_common_zone = max(set(zones), key=zones.count)

        types = [b["type"] for b in bookings]
        most_common_type = max(set(types), key=types.count)

        durations = []
        for b in bookings:
            start_time = b["startTime"]
            end_time = b["endTime"]

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∏–ø—É startTime —ñ endTime
            if isinstance(start_time, str):
                start_time = datetime.datetime.fromisoformat(start_time)
            if isinstance(end_time, str):
                end_time = datetime.datetime.fromisoformat(end_time)

            # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ
            durations.append((end_time - start_time).total_seconds() / 3600)

        avg_duration = np.mean(durations)

        start_hours = []
        for b in bookings:
            start_time = b["startTime"]

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∏–ø—É startTime
            if isinstance(start_time, str):
                start_time = datetime.datetime.fromisoformat(start_time)

            start_hours.append(start_time.hour)

        avg_start_hour = np.mean(start_hours)

        prices = [b["price"] for b in bookings]
        avg_price = np.mean(prices)

        # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_profile = {
            "userId": user_id,
            "username": user["username"],
            "email": user["email"],
            "most_common_zone": most_common_zone,
            "most_common_type": most_common_type,
            "avg_duration": avg_duration,
            "avg_start_hour": avg_start_hour,
            "avg_price": avg_price,
        }

        print(f"‚úÖ –ü—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Å—Ñ–æ—Ä–º–æ–≤–∞–Ω–æ: {user_profile}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        return jsonify(user_profile), 200

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {e}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–∫–∏
        return jsonify({"error": "Server error"}), 500
    
@app.route('/api/device-vectors', methods=['GET'])
def get_device_vectors():
    try:
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤ —ñ–∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
        devices = list(collection.find())
        if not devices:
            print("‚ùå –ü—Ä–∏—Å—Ç—Ä–æ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö.")
            return jsonify({"error": "No devices found"}), 404

        device_vectors = []
        for device in devices:
            zone = device.get("zone", "Unknown")  # –ó–æ–Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—é
            device_type = device.get("type", "Unknown")  # –¢–∏–ø –ø—Ä–∏—Å—Ç—Ä–æ—é

            # –Ü—Å—Ç–æ—Ä—ñ—è –±—Ä–æ–Ω—é–≤–∞–Ω—å
            bookings = device.get("bookings", [])
            if bookings:
                durations = []
                start_hours = []
                prices = []

                for booking in bookings:
                    start_time = booking["startTime"]
                    end_time = booking["endTime"]
                    price = booking.get("price", 0)

                    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∏–ø—É startTime —ñ endTime
                    if isinstance(start_time, str):
                        start_time = datetime.datetime.fromisoformat(start_time)
                    if isinstance(end_time, str):
                        end_time = datetime.datetime.fromisoformat(end_time)

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ
                    durations.append((end_time - start_time).total_seconds() / 3600)
                    start_hours.append(start_time.hour)
                    prices.append(price)

                avg_duration = np.mean(durations)
                avg_start_hour = np.mean(start_hours)
                avg_price = np.mean(prices)
            else:
                avg_duration = 0
                avg_start_hour = 0
                avg_price = 0

            # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏—Å—Ç—Ä–æ—é
            device_vector = {
                "deviceId": str(device["_id"]),  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è ObjectId —É —Ä—è–¥–æ–∫
                "id": device.get("id", "Unknown"),  # –î–æ–¥–∞—î–º–æ –Ω–∞–∑–≤—É –ø—Ä–∏—Å—Ç—Ä–æ—é (id)
                "zone": zone,
                "type": device_type,
                "avg_duration": avg_duration,
                "avg_start_hour": avg_start_hour,
                "avg_price": avg_price
            }
            device_vectors.append(device_vector)

        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤ —Å—Ñ–æ—Ä–º–æ–≤–∞–Ω–æ: {device_vectors}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
        return jsonify(device_vectors), 200

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤: {e}")
        return jsonify({"error": "Server error"}), 500

@app.route('/api/recommendations/<user_id>', methods=['GET'])
def get_recommendations(user_id):
    try:
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_profile_response = get_user_profile(user_id)
        if user_profile_response[1] != 200:
            return user_profile_response  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–º–∏–ª–∫—É, —è–∫—â–æ –ø—Ä–æ—Ñ—ñ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

        user_profile = user_profile_response[0].json
        #print(f"‚úÖ –ü—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {user_profile}")

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        device_vectors_response = get_device_vectors()
        if device_vectors_response[1] != 200:
            return device_vectors_response  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–º–∏–ª–∫—É, —è–∫—â–æ –ø—Ä–∏—Å—Ç—Ä–æ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

        device_vectors = device_vectors_response[0].json
        #print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–∏ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤: {device_vectors}")

        # One-hot encoding –¥–ª—è –∑–æ–Ω —ñ —Ç–∏–ø—ñ–≤
        encoder = OneHotEncoder()
        zones = [user_profile["most_common_zone"]] + [d["zone"] for d in device_vectors]
        types = [user_profile["most_common_type"]] + [d["type"] for d in device_vectors]

        zone_encoded = encoder.fit_transform(np.array(zones).reshape(-1, 1)).toarray()
        type_encoded = encoder.fit_transform(np.array(types).reshape(-1, 1)).toarray()

        # –ü–æ–±—É–¥–æ–≤–∞ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_vector = np.concatenate([
            zone_encoded[0],
            type_encoded[0],
            [user_profile["avg_duration"], user_profile["avg_start_hour"], user_profile["avg_price"]],
        ])

        # –ü–æ–±—É–¥–æ–≤–∞ –≤–µ–∫—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        device_vectors_encoded = [
            np.concatenate([
                zone_encoded[i + 1],
                type_encoded[i + 1],
                [d["avg_duration"], d["avg_start_hour"], d["avg_price"]],
            ])
            for i, d in enumerate(device_vectors)
        ]

        # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ—ó —Å—Ö–æ–∂–æ—Å—Ç—ñ
        similarities = cosine_similarity([user_vector], device_vectors_encoded)[0]
        print(f"‚úÖ –ö–æ—Å–∏–Ω—É—Å–Ω–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å: {similarities}")

        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
        sorted_devices = sorted(
            zip(device_vectors, similarities),
            key=lambda x: x[1],
            reverse=True
        )

        # –í–∏–±—ñ—Ä —Ç–æ–ø-3 –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        top_3_devices = [
            {
                "deviceId": d["deviceId"],
                "zone": d["zone"],
                "type": d["type"],
                "avg_duration": d["avg_duration"],
                "avg_start_hour": d["avg_start_hour"],
                "avg_price": d["avg_price"],
                "similarity": sim
            }
            for d, sim in sorted_devices[:3]
        ]

        print(f"‚úÖ –¢–æ–ø-3 –ø—Ä–∏—Å—Ç—Ä–æ—ó: {top_3_devices}")
        return jsonify(top_3_devices), 200

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {e}")
        return jsonify({"error": "Server error"}), 500
        

@app.route('/api/recommendations/filtered/<user_id>', methods=['GET'])
def get_recommendations_with_filter(user_id):
    try:
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_profile_response = get_user_profile(user_id)
        if user_profile_response[1] != 200:
            return user_profile_response  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–º–∏–ª–∫—É, —è–∫—â–æ –ø—Ä–æ—Ñ—ñ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

        user_profile = user_profile_response[0].json

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        device_vectors_response = get_device_vectors()
        if device_vectors_response[1] != 200:
            return device_vectors_response  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–º–∏–ª–∫—É, —è–∫—â–æ –ø—Ä–∏—Å—Ç—Ä–æ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

        device_vectors = device_vectors_response[0].json

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –±—Ä–æ–Ω—é–≤–∞–Ω—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        devices = db.devices.find({"bookings.userId": user_id})
        user_bookings = []
        for device in devices:
            for booking in device["bookings"]:
                if booking["userId"] == user_id:
                    user_bookings.append({
                        "deviceId": str(device["_id"]),
                        "startTime": booking["startTime"],
                        "endTime": booking["endTime"]
                    })

        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤, —è–∫—ñ –≤–∂–µ –∑–∞–±—Ä–æ–Ω—å–æ–≤–∞–Ω—ñ —É –Ω–∞–π–±–ª–∏–∂—á—ñ 2 –¥–Ω—ñ
        now = datetime.datetime.now()
        two_days_from_now = now + datetime.timedelta(days=2)

        booked_device_ids = set()
        for booking in user_bookings:
            start_time = booking["startTime"]
            if isinstance(start_time, str):
                start_time = datetime.datetime.fromisoformat(start_time)
            if now <= start_time < two_days_from_now:
                booked_device_ids.add(booking["deviceId"])

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø—Ä–∏—Å—Ç—Ä–æ—ó, —è–∫—ñ –Ω–µ –∑–∞–±—Ä–æ–Ω—å–æ–≤–∞–Ω—ñ
        filtered_devices = [
            device for device in device_vectors
            if device["deviceId"] not in booked_device_ids and (
                device["avg_duration"] > 0 or device["avg_price"] > 0 or device["avg_start_hour"] > 0
            )
        ]

        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ —Ç–∞ —Ü—ñ–Ω–∏
        def get_closest_duration(durations, target_duration):
            return min(durations, key=lambda x: abs(x - target_duration))

        for d in filtered_devices:
            available_durations = [int(duration) for duration in price_table_collection.find_one({"zone": d["zone"]})["prices"].keys()]
            if available_durations:
                d["avg_duration"] = get_closest_duration(available_durations, d["avg_duration"])
                d["avg_price"] = calculate_price(d["zone"], d["avg_duration"])
            else:
                d["avg_duration"] = 1
                d["avg_price"] = 0

        # One-hot encoding –¥–ª—è –∑–æ–Ω —ñ —Ç–∏–ø—ñ–≤
        encoder = OneHotEncoder()
        zones = [user_profile["most_common_zone"]] + [d["zone"] for d in filtered_devices]
        types = [user_profile["most_common_type"]] + [d["type"] for d in filtered_devices]

        zone_encoded = encoder.fit_transform(np.array(zones).reshape(-1, 1)).toarray()
        type_encoded = encoder.fit_transform(np.array(types).reshape(-1, 1)).toarray()

        # –ü–æ–±—É–¥–æ–≤–∞ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–æ—Ñ—ñ–ª—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_vector = np.concatenate([
            zone_encoded[0],
            type_encoded[0],
            [user_profile["avg_duration"] * 2,  # –í–∞–≥–∞ —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ
             user_profile["avg_start_hour"] * 1.5,  # –í–∞–≥–∞ —á–∞—Å—É –ø–æ—á–∞—Ç–∫—É
             user_profile["avg_price"]]
        ])

        # –ü–æ–±—É–¥–æ–≤–∞ –≤–µ–∫—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        device_vectors_encoded = [
            np.concatenate([
                zone_encoded[i + 1],
                type_encoded[i + 1],
                [d["avg_duration"], d["avg_start_hour"], d["avg_price"]],
            ])
            for i, d in enumerate(filtered_devices)
        ]

        # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ—ó —Å—Ö–æ–∂–æ—Å—Ç—ñ
        similarities = cosine_similarity([user_vector], device_vectors_encoded)[0]

        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
        sorted_devices = sorted(
            zip(filtered_devices, similarities),
            key=lambda x: x[1],
            reverse=True
        )

        # –í–∏–±—ñ—Ä —Ç–æ–ø-3 –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        top_3_devices = [
            {
                "deviceId": d["deviceId"],
                "id": d.get("id", "Unknown"),  # –î–æ–¥–∞—î–º–æ –Ω–∞–∑–≤—É –ø—Ä–∏—Å—Ç—Ä–æ—é (id)
                "zone": d["zone"],
                "type": d["type"],
                "avg_duration": d["avg_duration"],
                "avg_start_hour": d["avg_start_hour"],
                "avg_price": d["avg_price"],
                "similarity": sim
            }
            for d, sim in sorted_devices[:3]
        ]

        print(f"‚úÖ –¢–æ–ø-3 –ø—Ä–∏—Å—Ç—Ä–æ—ó –ø—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó: {top_3_devices}")
        return jsonify(top_3_devices), 200

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {e}")
        return jsonify({"error": "Server error"}), 500

from prediction.model import train_and_predict

@app.route('/api/custom-predict', methods=['POST'])
def custom_predict():
    try:
        data = request.get_json()
        train_from = data.get("trainFrom")
        train_to = data.get("trainTo")
        predict_from = data.get("predictFrom")
        predict_to = data.get("predictTo")
        use_all = data.get("useAll", False)

        result = train_and_predict(train_from, train_to, predict_from, predict_to, use_all=use_all)
        return jsonify(result), 200
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —É /api/custom-predict: {e}")
        return jsonify({"error": str(e)}), 500
  

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
